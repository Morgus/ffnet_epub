#!/usr/bin/env python
# 2014 Aleksi Blinnikka

import argparse, threading, sys, queue, backend
from urllib.parse import urlparse

def main():
    parser = argparse.ArgumentParser(
            description="Create Epub documents from fanfiction online.")
    parser.add_argument("-c", "--connections", default=2, type=int,
            help="maximum number of simultaneous connections (default 2)")
    parser.add_argument("URL", type=parse_url, help="URL of the first chapter")
    parser.add_argument("FILE", nargs="?",
            help="path where the Epub will be saved to")
    parser.add_argument("-v", "--version", action="version",
            version="Fanfic downloader 1.0, 2014 Aleksi Blinnikka")
    args = parser.parse_args()

    print("Downloading story from {}".format(args.URL))
    progress_queue = backend.progress_queue
    creator_thread = threading.Thread(target=backend.create_document,
            args=(args.URL, args.connections, args.FILE), daemon=True)
    creator_thread.start()
    ch_done = 0
    chapters = 0
    while True:
        try:
            progress = progress_queue.get(timeout=1)
        except queue.Empty:
            pass
        else:
            ch_done += 1
            if not progress[0]:
                print(progress[1])
                chapters = -1
                break
            elif progress[1]:
                chapters = progress[1]
            print("{}/{} chapters done".format(ch_done, chapters))
        if not creator_thread.is_alive():
            break
    if chapters <= 0:
        sys.exit(1)
    print("Done!")

def parse_url(url):
    result = urlparse(url)
    if not result.netloc or not result.path:
        msg = "{} not a valid URL (maybe missing http(s)://?)".format(url)
        raise argparse.ArgumentTypeError(msg)
    return url

if __name__ == "__main__":
    main()

