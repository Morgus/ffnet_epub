#!/usr/bin/env python
# 2014 Aleksi Blinnikka

import argparse, threading, sys, queue
from urllib.parse import urlparse
import backend

def main():
    parser = argparse.ArgumentParser(
            description="Create Epub documents from fanfiction online.",
            formatter_class=argparse.RawTextHelpFormatter)
    parser.add_argument("-c", "--connections", default=2, type=int,
        help="maximum number of simultaneous connections (default 2)")
    parser.add_argument("-f", "--file",
     help="filename for the resulting Epub\n(default <author> - <title>.epub)")
    parser.add_argument("URL", type=parse_url, help="URL of the first chapter")
    parser.add_argument("--version", action="version",
            version="Fanfic downloader 1.0\n2014 Aleksi Blinnikka")
    args = parser.parse_args()

    print("Downloading story from {}".format(args.URL))
    progress_queue = backend.progress_queue
    creator_thread = threading.Thread(target=backend.create_document,
            args=(args.URL, args.connections, args.file))
    creator_thread.start()
    ch_done = 0
    chapters = 0
    while True:
        try:
            progress = progress_queue.get(timeout=1)
        except queue.Empty:
            pass
        else:
            ch_done += 1
            if progress[1]:
                chapters = progress[1]
            print("{}/{} chapters done".format(ch_done, chapters))
            progress_queue.task_done()
        if not creator_thread.is_alive():
            break
    print("Done!")

def parse_url(url):
    result = urlparse(url)
    if not result.netloc or not result.path:
        msg = "{} not a valid URL (maybe missing http(s)://?)".format(url)
        raise argparse.ArgumentTypeError(msg)
    return url

if __name__ == "__main__":
    main()

